{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Histogram-Tugas 5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAw8OWT4Cc5EZQ+pvNVqec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faiqazmi/RepoTugasBesar_TKC_047_059/blob/main/Histogram_Tugas_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZEcGwsAzkBw"
      },
      "source": [
        "# **color_correction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5D-bdijzD67"
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils.perspective import four_point_transform\n",
        "from skimage import exposure\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaZQLKl5z0wV"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPU0FHXOz2Kh"
      },
      "source": [
        "def find_color_card(image):\n",
        "\t# load the ArUCo dictionary, grab the ArUCo parameters, and\n",
        "\t# detect the markers in the input image\n",
        "\tarucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL)\n",
        "\tarucoParams = cv2.aruco.DetectorParameters_create()\n",
        "\t(corners, ids, rejected) = cv2.aruco.detectMarkers(image,\n",
        "\t\tarucoDict, parameters=arucoParams)\n",
        "\n",
        "\t# try to extract the coordinates of the color correction card\n",
        "\ttry:\n",
        "\t\t# otherwise, we've found the four ArUco markers, so we can\n",
        "\t\t# continue by flattening the ArUco IDs list\n",
        "\t\tids = ids.flatten()\n",
        "\n",
        "\t\t# extract the top-left marker\n",
        "\t\ti = np.squeeze(np.where(ids == 923))\n",
        "\t\ttopLeft = np.squeeze(corners[i])[0]\n",
        "\n",
        "\t\t# extract the top-right marker\n",
        "\t\ti = np.squeeze(np.where(ids == 1001))\n",
        "\t\ttopRight = np.squeeze(corners[i])[1]\n",
        "\n",
        "\t\t# extract the bottom-right marker\n",
        "\t\ti = np.squeeze(np.where(ids == 241))\n",
        "\t\tbottomRight = np.squeeze(corners[i])[2]\n",
        "\n",
        "\t\t# extract the bottom-left marker\n",
        "\t\ti = np.squeeze(np.where(ids == 1007))\n",
        "\t\tbottomLeft = np.squeeze(corners[i])[3]\n",
        "\n",
        "\t# we could not find color correction card, so gracefully return\n",
        "\texcept:\n",
        "\t\treturn None\n",
        "\n",
        "\t# build our list of reference points and apply a perspective\n",
        "\t# transform to obtain a top-down, birds-eye-view of the color\n",
        "\t# matching card\n",
        "\tcardCoords = np.array([topLeft, topRight,\n",
        "\t\tbottomRight, bottomLeft])\n",
        "\tcard = four_point_transform(image, cardCoords)\n",
        "\n",
        "\t# return the color matching card to the calling function\n",
        "\treturn card"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdM3jkQZz23S"
      },
      "source": [
        "args = {\n",
        "    \"reference\": \"reference.jpg\",\n",
        "    \"input\": \"01.jpg\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDstKSlpz5ob"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "ref = cv2.imread(args[\"reference\"])\n",
        "image = cv2.imread(args[\"input\"])\n",
        "\n",
        "# resize the reference and input images\n",
        "ref = imutils.resize(ref, width=600)\n",
        "image = imutils.resize(image, width=600)\n",
        "\n",
        "# display the reference and input images to our screen\n",
        "plt_imshow(\"Reference\", ref)\n",
        "plt_imshow(\"Input\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmzQdqUz3_h"
      },
      "source": [
        "print(\"[INFO] finding color matching cards...\")\n",
        "refCard = find_color_card(ref)\n",
        "imageCard = find_color_card(image)\n",
        "\n",
        "# if the color matching card is not found in either the reference\n",
        "# image or the input image, gracefully exit\n",
        "if refCard is None or imageCard is None:\n",
        "\tprint(\"[INFO] could not find color matching card in both images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3YvyYrz-Ga"
      },
      "source": [
        "plt_imshow(\"Reference Color Card\", refCard)\n",
        "plt_imshow(\"Input Color Card\", imageCard)\n",
        "\n",
        "# apply histogram matching from the color matching card in the\n",
        "# reference image to the color matching card in the input image\n",
        "print(\"[INFO] matching images...\")\n",
        "imageCard = exposure.match_histograms(imageCard, refCard,\n",
        "\tmultichannel=True)\n",
        "\n",
        "# show our input color matching card after histogram matching\n",
        "plt_imshow(\"Input Color Card After Matching\", imageCard)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o23kEOZe0Ikq"
      },
      "source": [
        "# **hi_detect_low_contrast**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdPIpBCRz_qE"
      },
      "source": [
        "from skimage.exposure import is_low_contrast\n",
        "from imutils.paths import list_images\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yhFCxzW0MYL"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show("
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A82AIm4K0PLB"
      },
      "source": [
        "args = {\n",
        "    \"input\": \"examples\",\n",
        "    \"thresh\": 0.35\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0FA6naP0Qwa"
      },
      "source": [
        "# grab the paths to the input images\n",
        "imagePaths = sorted(list(list_images(args[\"input\"])))\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# load the input image from disk, resize it, and convert it to\n",
        "\t# grayscale\n",
        "\tprint(\"[INFO] processing image {}/{}\".format(i + 1,\n",
        "\t\tlen(imagePaths)))\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = imutils.resize(image, width=450)\n",
        "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\t# blur the image slightly and perform edge detection\n",
        "\tblurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\tedged = cv2.Canny(blurred, 30, 150)\n",
        "\n",
        "\t# initialize the text and color to indicate that the input image\n",
        "\t# is *not* low contrast\n",
        "\ttext = \"Low contrast: No\"\n",
        "\tcolor = (0, 255, 0)\n",
        "\n",
        "\t# check to see if the image is low contrast\n",
        "\tif is_low_contrast(gray, fraction_threshold=args[\"thresh\"]):\n",
        "\t\t# update the text and color\n",
        "\t\ttext = \"Low contrast: Yes\"\n",
        "\t\tcolor = (0, 0, 255)\n",
        "\n",
        "\t# otherwise, the image is *not* low contrast, so we can continue\n",
        "\t# processing it\n",
        "\telse:\n",
        "\t\t# find contours in the edge map and find the largest one,\n",
        "\t\t# which we'll assume is the outline of our color correction\n",
        "\t\t# card\n",
        "\t\tcnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\tcnts = imutils.grab_contours(cnts)\n",
        "\t\tc = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\t\t# draw the largest contour on the image\n",
        "\t\tcv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
        "\n",
        "\t# draw the text on the output image\n",
        "\tcv2.putText(image, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
        "\t\tcolor, 2)\n",
        "\n",
        "\t# show the output image and edge map\n",
        "\tplt_imshow(\"Image\", image)\n",
        "\tplt_imshow(\"Edge\", edged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKt7GETI0R4j"
      },
      "source": [
        "args = {\n",
        "    \"input\": \"example_video.mp4\",\n",
        "    \"thresh\": 0.35,\n",
        "    \"output\": \"output.avi\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K0qO1t70TtE"
      },
      "source": [
        "print(\"[INFO] accessing video stream...\")\n",
        "vs = cv2.VideoCapture(args[\"input\"] if args[\"input\"] else 0)\n",
        "writer = None\n",
        "\n",
        "# loop over frames from the video stream\n",
        "while True:\n",
        "\t# read a frame from the video stream\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\n",
        "\t# if the frame was not grabbed then we've reached the end of\n",
        "\t# the video stream so exit the script\n",
        "\tif not grabbed:\n",
        "\t\tprint(\"[INFO] no frame read from stream - exiting\")\n",
        "\t\tbreak\n",
        "\n",
        "\t# resize the frame, convert it to grayscale, blur it, and then\n",
        "\t# perform edge detection\n",
        "\tframe = imutils.resize(frame, width=450)\n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\tblurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\tedged = cv2.Canny(blurred, 30, 150)\n",
        "\n",
        "\t# initialize the text and color to indicate that the current\n",
        "\t# frame is *not* low contrast\n",
        "\ttext = \"Low contrast: No\"\n",
        "\tcolor = (0, 255, 0)\n",
        "\n",
        "\t# check to see if the frame is low contrast, and if so, update\n",
        "\t# the text and color\n",
        "\tif is_low_contrast(gray, fraction_threshold=args[\"thresh\"]):\n",
        "\t\ttext = \"Low contrast: Yes\"\n",
        "\t\tcolor = (0, 0, 255)\n",
        "\n",
        "\t# otherwise, the frame is *not* low contrast, so we can continue\n",
        "\t# processing it\n",
        "\telse:\n",
        "\t\t# find contours in the edge map and find the largest one,\n",
        "\t\t# which we'll assume is the outline of our color correction\n",
        "\t\t# card\n",
        "\t\tcnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\tcnts = imutils.grab_contours(cnts)\n",
        "\t\tc = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\t\t# draw the largest contour on the frame\n",
        "\t\tcv2.drawContours(frame, [c], -1, (0, 255, 0), 2)\n",
        "\n",
        "\t# draw the text on the output frame\n",
        "\tcv2.putText(frame, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
        "\t\tcolor, 2)\n",
        "\n",
        "\t# stack the output frame and edge map next to each other\n",
        "\toutput = np.dstack([edged] * 3)\n",
        "\toutput = np.hstack([frame, output])\n",
        "\n",
        "    # if the video writer is None *AND* we are supposed to write\n",
        "\t# the output video to disk initialize the writer\n",
        "\tif writer is None and args[\"output\"] is not None:\n",
        "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 20,\n",
        "\t\t\t(output.shape[1], output.shape[0]), True)\n",
        "  \n",
        "    # if the writer is not None, write the frame to disk\n",
        "\tif writer is not None:\n",
        "\t\twriter.write(output)\n",
        "  \n",
        "# do a bit of cleanup\n",
        "vs.release()\n",
        "vs.release()\n",
        "\n",
        "# check to see if the video writer point needs to be released\n",
        "if writer is not None:\n",
        "\twriter.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNm6oqxV0Vmn"
      },
      "source": [
        "\n",
        "!ffmpeg -i \"output.avi\" output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmFX0M020ZWj"
      },
      "source": [
        "#@title Display video inline\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open(\"output.mp4\", \"rb\").read()\n",
        "dataURL = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=700 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % dataURL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRASiCyJ0hge"
      },
      "source": [
        "# **gamma_correction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yu_aEtI0ihD"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jy7-ozE0ldE"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "\t# convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFs4i1x00oSP"
      },
      "source": [
        "def adjust_gamma(image, gamma=1.0):\n",
        "\t# build a lookup table mapping the pixel values [0, 255] to\n",
        "\t# their adjusted gamma values\n",
        "\tinvGamma = 1.0 / gamma\n",
        "\ttable = np.array([((i / 255.0) ** invGamma) * 255\n",
        "\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "\n",
        "\t# apply gamma correction using the lookup table\n",
        "\treturn cv2.LUT(image, table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33eUZZ180pf9"
      },
      "source": [
        "args = {\n",
        "\t\"image\": \"batik1.jpg\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBz53ejo0qkX"
      },
      "source": [
        "# load the original image\n",
        "original = cv2.imread(args[\"image\"])\n",
        "\n",
        "# loop over various values of gamma\n",
        "for gamma in np.arange(0.0, 3.5, 0.5):\n",
        "\t# ignore when gamma is 1 (there will be no change to the image)\n",
        "\tif gamma == 1:\n",
        "\t\tcontinue\n",
        "\n",
        "\t# apply gamma correction and show the images\n",
        "\tgamma = gamma if gamma > 0 else 0.1\n",
        "\tadjusted = adjust_gamma(original, gamma=gamma)\n",
        "\tcv2.putText(adjusted, \"g={}\".format(gamma), (10, 30),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
        "\tplt_imshow(\"Images\", np.hstack([original, adjusted]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sDWdN770r29"
      },
      "source": [
        "# **histogram**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov_-xl7P06bR"
      },
      "source": [
        "# import the necessary packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzsPWHAq07vj"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.grid(False)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "306_NV85083I"
      },
      "source": [
        "def plot_histogram(image, title, mask=None):\n",
        "\t# split the image into its respective channels, then initialize\n",
        "\t# the tuple of channel names along with our figure for plotting\n",
        "\tchans = cv2.split(image)\n",
        "\tcolors = (\"b\", \"g\", \"r\")\n",
        "\tplt.figure()\n",
        "\tplt.title(title)\n",
        "\tplt.xlabel(\"Bins\")\n",
        "\tplt.ylabel(\"# of Pixels\")\n",
        "\n",
        "\t# loop over the image channels\n",
        "\tfor (chan, color) in zip(chans, colors):\n",
        "\t\t# create a histogram for the current channel and plot it\n",
        "\t\thist = cv2.calcHist([chan], [0], mask, [256], [0, 256])\n",
        "\t\tplt.plot(hist, color=color)\n",
        "\t\tplt.xlim([0, 256])\n",
        "\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqqLsnTP0-BK"
      },
      "source": [
        "args = {\n",
        "    \"image\": \"beach.png\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJjMGugr0_cJ"
      },
      "source": [
        "\n",
        "# load the input image and convert it to grayscale\n",
        "image = cv2.imread(args[\"image\"])\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lyyFRfC1ARd"
      },
      "source": [
        "\n",
        "# compute a grayscale histogram\n",
        "hist = cv2.calcHist([image], [0], None, [256], [0, 256])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62OsedZw1Bx3"
      },
      "source": [
        "# matplotlib expects RGB images so convert and then display the image\n",
        "# with matplotlib\n",
        "plt.figure()\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\n",
        "\n",
        "# plot the histogram\n",
        "plt.figure()\n",
        "plt.title(\"Grayscale Histogram\")\n",
        "plt.xlabel(\"Bins\")\n",
        "plt.ylabel(\"# of Pixels\")\n",
        "plt.plot(hist)\n",
        "plt.xlim([0, 256])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMQUUZ5d1C_x"
      },
      "source": [
        "# normalize the histogram\n",
        "hist /= hist.sum()\n",
        "\n",
        "# plot the normalized histogram\n",
        "plt.figure()\n",
        "plt.title(\"Grayscale Histogram (Normalized)\")\n",
        "plt.xlabel(\"Bins\")\n",
        "plt.ylabel(\"% of Pixels\")\n",
        "plt.plot(hist)\n",
        "plt.xlim([0, 256])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDCpXB1x1EPV"
      },
      "source": [
        "# load the input image from disk\n",
        "image = cv2.imread(args[\"image\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaZnoKpT1FQZ"
      },
      "source": [
        "# split the image into its respective channels, then initialize the\n",
        "# tuple of channel names along with our figure for plotting\n",
        "chans = cv2.split(image)\n",
        "colors = (\"b\", \"g\", \"r\")\n",
        "plt.figure()\n",
        "plt.title(\"'Flattened' Color Histogram\")\n",
        "plt.xlabel(\"Bins\")\n",
        "plt.ylabel(\"# of Pixels\")\n",
        "\n",
        "# loop over the image channels\n",
        "for (chan, color) in zip(chans, colors):\n",
        "\t# create a histogram for the current channel and plot it\n",
        "\thist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n",
        "\tplt.plot(hist, color=color)\n",
        "\tplt.xlim([0, 256])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU2Ui2CJ1Gf0"
      },
      "source": [
        "# create a new figure and then plot a 2D color histogram for the\n",
        "# green and blue channels\n",
        "fig = plt.figure(figsize=(15, 25))\n",
        "ax = fig.add_subplot(131)\n",
        "hist = cv2.calcHist([chans[1], chans[0]], [0, 1], None, [32, 32],\n",
        "\t[0, 256, 0, 256])\n",
        "p = ax.imshow(hist, interpolation=\"nearest\")\n",
        "ax.set_title(\"2D Color Histogram for G and B\")\n",
        "plt.colorbar(p)\n",
        "\n",
        "# plot a 2D color histogram for the green and red channels\n",
        "ax = fig.add_subplot(132)\n",
        "hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None, [32, 32],\n",
        "\t[0, 256, 0, 256])\n",
        "p = ax.imshow(hist, interpolation=\"nearest\")\n",
        "ax.set_title(\"2D Color Histogram for G and R\")\n",
        "plt.colorbar(p)\n",
        "\n",
        "# plot a 2D color histogram for blue and red channels\n",
        "ax = fig.add_subplot(133)\n",
        "hist = cv2.calcHist([chans[0], chans[2]], [0, 1], None, [32, 32],\n",
        "\t[0, 256, 0, 256])\n",
        "p = ax.imshow(hist, interpolation=\"nearest\")\n",
        "ax.set_title(\"2D Color Histogram for B and R\")\n",
        "plt.colorbar(p)\n",
        "\n",
        "# finally, let's examine the dimensionality of one of the 2D\n",
        "# histograms\n",
        "print(\"2D histogram shape: {}, with {} values\".format(\n",
        "\thist.shape, hist.flatten().shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lzc6Cej1IKL"
      },
      "source": [
        "# our 2D histogram could only take into account 2 out of the 3\n",
        "# channels in the image so now let's build a 3D color histogram\n",
        "# (utilizing all channels) with 8 bins in each direction -- we\n",
        "# can't plot the 3D histogram, but the theory is exactly like\n",
        "# that of a 2D histogram, so we'll just show the shape of the\n",
        "# histogram\n",
        "hist = cv2.calcHist([image], [0, 1, 2],\n",
        "\tNone, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "print(\"3D histogram shape: {}, with {} values\".format(\n",
        "\thist.shape, hist.flatten().shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwWzF6AF1Jfk"
      },
      "source": [
        "# display the original input image\n",
        "plt.figure()\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(imutils.opencv2matplotlib(image))\n",
        "\n",
        "# show our plots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqrf_ZBr1Ktx"
      },
      "source": [
        "# load the beach image and plot a histogram for it\n",
        "image = cv2.imread(\"beach.png\")\n",
        "plot_histogram(image, \"Histogram for Original Image\")\n",
        "plt_imshow(\"Original\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKUxwpp-1MGf"
      },
      "source": [
        "# construct a mask for our image; our mask will be *black* for regions\n",
        "# we want to *ignore* and *white* for regions we want to *examine*\n",
        "mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
        "cv2.rectangle(mask, (60, 290), (210, 390), 255, -1)\n",
        "plt_imshow(\"Mask\", mask)\n",
        "\n",
        "# display the masked region\n",
        "masked = cv2.bitwise_and(image, image, mask=mask)\n",
        "plt_imshow(\"Applying the Mask\", masked)\n",
        "\n",
        "# compute a histogram for our image, but we'll only include pixels in\n",
        "# the masked region\n",
        "plot_histogram(image, \"Histogram for Masked Image\", mask=mask)\n",
        "\n",
        "# show our plots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD6ZQDSP1OaA"
      },
      "source": [
        "**Histogram Equalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6AQ3MVU1TrB"
      },
      "source": [
        "# import the necessary packages\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXt4RJIo1W5m"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QajqcCJZ1YXy"
      },
      "source": [
        "args = {\n",
        "    \"image\": \"dog.png\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3gAT7WJ1Z5V"
      },
      "source": [
        "print(\"[INFO] loading input image...\")\n",
        "image = cv2.imread(args[\"image\"])\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# apply histogram equalization\n",
        "print(\"[INFO] performing histogram equalization...\")\n",
        "equalized = cv2.equalizeHist(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIMtXjtg1a76"
      },
      "source": [
        "plt_imshow(\"Input\", gray)\n",
        "plt_imshow(\"Histogram Equalization\", equalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAr8X0hp1cGM"
      },
      "source": [
        "args = {\n",
        "    \"image\": \"dog.png\",\n",
        "    \"clip\": 2.0,\n",
        "    \"tile\": 8\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1RVcMXy1dah"
      },
      "source": [
        "print(\"[INFO] loading input image...\")\n",
        "image = cv2.imread(args[\"image\"])\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "print(\"[INFO] applying CLAHE...\")\n",
        "clahe = cv2.createCLAHE(clipLimit=args[\"clip\"],\n",
        "\ttileGridSize=(args[\"tile\"], args[\"tile\"]))\n",
        "equalized = clahe.apply(gray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd534dOP1eZM"
      },
      "source": [
        "plt_imshow(\"Input\", gray)\n",
        "plt_imshow(\"CLAHE\", equalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5dQ_lfl1fOX"
      },
      "source": [
        "**histogram_matching**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5A87QAU1u73"
      },
      "source": [
        "from skimage import exposure\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2w-4Gt71yCU"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdtjInsr1wsS"
      },
      "source": [
        "args = {\n",
        "    \"source\": \"empire_state_cloudy.png\",\n",
        "    \"reference\": \"empire_state_sunset.png\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AzwKkDn11sT"
      },
      "source": [
        "# load the source and reference images\n",
        "print(\"[INFO] loading source and reference images...\")\n",
        "src = cv2.imread(args[\"source\"])\n",
        "ref = cv2.imread(args[\"reference\"])\n",
        "\n",
        "# determine if we are performing multichannel histogram matching\n",
        "# and then perform histogram matching itself\n",
        "print(\"[INFO] performing histogram matching...\")\n",
        "multi = True if src.shape[-1] > 1 else False\n",
        "matched = exposure.match_histograms(src, ref, multichannel=multi)\n",
        "\n",
        "# show the output images\n",
        "plt_imshow(\"Source\", src)\n",
        "plt_imshow(\"Reference\", ref)\n",
        "plt_imshow(\"Matched\", matched)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNNy6jek13gv"
      },
      "source": [
        "# construct a figure to display the histogram plots for each channel\n",
        "# before and after histogram matching was applied\n",
        "(fig, axs) =  plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
        "\n",
        "# loop over our source image, reference image, and output matched\n",
        "# image\n",
        "for (i, image) in enumerate((src, ref, matched)):\n",
        "\t# convert the image from BGR to RGB channel ordering\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\t# loop over the names of the channels in RGB order\n",
        "\tfor (j, color) in enumerate((\"red\", \"green\", \"blue\")):\n",
        "\t\t# compute a histogram for the current channel and plot it\n",
        "\t\t(hist, bins) = exposure.histogram(image[..., j],\n",
        "\t\t\tsource_range=\"dtype\")\n",
        "\t\taxs[j, i].plot(bins, hist / hist.max())\n",
        "\n",
        "\t\t# compute the cumulative distribution function for the\n",
        "\t\t# current channel and plot it\n",
        "\t\t(cdf, bins) = exposure.cumulative_distribution(image[..., j])\n",
        "\t\taxs[j, i].plot(bins, cdf)\n",
        "\n",
        "\t\t# set the y-axis label of the current plot to be the name\n",
        "\t\t# of the current color channel\n",
        "\t\taxs[j, 0].set_ylabel(color)\n",
        "  \n",
        "# set the axes titles\n",
        "axs[0, 0].set_title(\"Source\")\n",
        "axs[0, 1].set_title(\"Reference\")\n",
        "axs[0, 2].set_title(\"Matched\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH-z-Mbe13jL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}